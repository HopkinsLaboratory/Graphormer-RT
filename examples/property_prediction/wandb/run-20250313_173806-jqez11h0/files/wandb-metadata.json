{
    "os": "Linux-6.8.0-52-generic-x86_64-with-glibc2.35",
    "python": "3.9.18",
    "heartbeatAt": "2025-03-13T21:38:07.042088",
    "startedAt": "2025-03-13T21:38:06.688498",
    "docker": null,
    "cuda": null,
    "args": [
        "--user-dir",
        "../../graphormer",
        "--batch-size",
        "64",
        "--batch-size",
        "64",
        "--num-workers",
        "20",
        "--ddp-backend=legacy_ddp",
        "--seed",
        "23",
        "--user-data-dir",
        "HILIC_train",
        "--dataset-name",
        "RT_Library",
        "--task",
        "graph_prediction_with_flag",
        "--criterion",
        "rmse_HILIC",
        "--arch",
        "graphormer_HILIC",
        "--num-classes",
        "1",
        "--attention-dropout",
        "0.10",
        "--act-dropout",
        "0.10",
        "--dropout",
        "0.10",
        "--optimizer",
        "adam",
        "--adam-betas",
        "(0.9, 0.999)",
        "--adam-eps",
        "1e-8",
        "--clip-norm",
        "5.0",
        "--weight-decay",
        "0.01",
        "--lr-scheduler",
        "polynomial_decay",
        "--power",
        "1",
        "--warmup-updates",
        "59",
        "--total-num-update",
        "391",
        "--min-loss-scale",
        "1e-9",
        "--lr",
        "1.5e-4",
        "--fp16",
        "--encoder-layers",
        "8",
        "--wandb-project",
        "RT_preds",
        "--encoder-embed-dim",
        "512",
        "--encoder-ffn-embed-dim",
        "512",
        "--encoder-attention-heads",
        "64",
        "--mlp-layers",
        "5",
        "--max-epoch",
        "250",
        "--no-epoch-checkpoints",
        "--save-dir",
        "../../checkpoints"
    ],
    "state": "running",
    "program": "/home/cmkstien/anaconda3/envs/graphormer/bin/fairseq-train",
    "codePathLocal": null,
    "git": {
        "remote": "https://github.com/cmkstien/Graphormer_RT",
        "commit": "7a4513e00efa7afa34b6f48f33472bd5b10b1f23"
    },
    "email": "cmkstien@uwaterloo.ca",
    "root": "/home/cmkstien/RT_pub/Graphormer_RT",
    "host": "CroutonI",
    "username": "cmkstien",
    "executable": "/home/cmkstien/anaconda3/envs/graphormer/bin/python",
    "cpu_count": 24,
    "cpu_count_logical": 32,
    "cpu_freq": {
        "current": 1.1696250000000001,
        "min": 800.0,
        "max": 4937.5
    },
    "cpu_freq_per_core": [
        {
            "current": 1.132,
            "min": 800.0,
            "max": 5500.0
        },
        {
            "current": 1.117,
            "min": 800.0,
            "max": 5500.0
        },
        {
            "current": 2.577,
            "min": 800.0,
            "max": 5500.0
        },
        {
            "current": 0.8,
            "min": 800.0,
            "max": 5500.0
        },
        {
            "current": 2.194,
            "min": 800.0,
            "max": 5800.0
        },
        {
            "current": 0.8,
            "min": 800.0,
            "max": 5800.0
        },
        {
            "current": 1.11,
            "min": 800.0,
            "max": 5800.0
        },
        {
            "current": 0.8,
            "min": 800.0,
            "max": 5800.0
        },
        {
            "current": 0.8,
            "min": 800.0,
            "max": 5500.0
        },
        {
            "current": 0.8,
            "min": 800.0,
            "max": 5500.0
        },
        {
            "current": 0.8,
            "min": 800.0,
            "max": 5500.0
        },
        {
            "current": 0.8,
            "min": 800.0,
            "max": 5500.0
        },
        {
            "current": 0.8,
            "min": 800.0,
            "max": 5500.0
        },
        {
            "current": 0.8,
            "min": 800.0,
            "max": 5500.0
        },
        {
            "current": 0.8,
            "min": 800.0,
            "max": 5500.0
        },
        {
            "current": 0.8,
            "min": 800.0,
            "max": 5500.0
        },
        {
            "current": 0.951,
            "min": 800.0,
            "max": 4300.0
        },
        {
            "current": 0.8,
            "min": 800.0,
            "max": 4300.0
        },
        {
            "current": 0.8,
            "min": 800.0,
            "max": 4300.0
        },
        {
            "current": 0.8,
            "min": 800.0,
            "max": 4300.0
        },
        {
            "current": 0.801,
            "min": 800.0,
            "max": 4300.0
        },
        {
            "current": 1.227,
            "min": 800.0,
            "max": 4300.0
        },
        {
            "current": 0.8,
            "min": 800.0,
            "max": 4300.0
        },
        {
            "current": 0.846,
            "min": 800.0,
            "max": 4300.0
        },
        {
            "current": 0.8,
            "min": 800.0,
            "max": 4300.0
        },
        {
            "current": 0.8,
            "min": 800.0,
            "max": 4300.0
        },
        {
            "current": 0.8,
            "min": 800.0,
            "max": 4300.0
        },
        {
            "current": 0.8,
            "min": 800.0,
            "max": 4300.0
        },
        {
            "current": 0.8,
            "min": 800.0,
            "max": 4300.0
        },
        {
            "current": 0.838,
            "min": 800.0,
            "max": 4300.0
        },
        {
            "current": 0.8,
            "min": 800.0,
            "max": 4300.0
        },
        {
            "current": 0.8,
            "min": 800.0,
            "max": 4300.0
        }
    ],
    "disk": {
        "/": {
            "total": 1832.2072448730469,
            "used": 1232.2831115722656
        }
    },
    "gpu": "NVIDIA GeForce RTX 4090",
    "gpu_count": 1,
    "gpu_devices": [
        {
            "name": "NVIDIA GeForce RTX 4090",
            "memory_total": 25757220864
        }
    ],
    "memory": {
        "total": 62.56400680541992
    }
}
